# Model-Selection_Technique_and_-hyperparameter-searches_with_python
With the growth of machine learning, there is an evergrowing list of algorithms that can be used to model data. In previous notebooks, we have introduced many of the most popular machine learning algorithms, including linear and logistic regression, support vector machine, decision trees, k-nearest neighbors, and ensemble techniques like random forest. In addition, these algorithms all have their own set of hyperparameters whose values, for optimal performance, must be carefully selected.  As a result, selecting the best model and associated set of hyperparameters can be a daunting task. In this notebook, we explore the topic of Model Selection by first manually evaluating one hyperparameter for one machine learning algorithm on a specific data set. This will introduce the basic concepts required to perform model selection, before we move into more automated techniques with help of cross-validation which is introduced in the previous lesson. Following this, we will look at grid searches to find the best combinations of multiple hyperparameters. Finally, we will look at additional model selection techniques such as random hyperparameter searches.
